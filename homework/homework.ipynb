{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 0. Cargue archivos pkl (validación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JUAN\\anaconda3\\envs\\envML\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "ruta_archivo = \"../files/grading/x_train.pkl\"\n",
    "\n",
    "with open(ruta_archivo, \"rb\") as file:\n",
    "    contenido1 = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_archivo = \"../files/grading/y_train.pkl\"\n",
    "\n",
    "with open(ruta_archivo, \"rb\") as file:\n",
    "    contenido2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_archivo = \"../files/grading/x_test.pkl\"\n",
    "\n",
    "with open(ruta_archivo, \"rb\") as file:\n",
    "    contenido3 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_archivo = \"../files/grading/y_test.pkl\"\n",
    "\n",
    "with open(ruta_archivo, \"rb\") as file:\n",
    "    contenido4 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 1. Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                            0\n",
      "LIMIT_BAL                     0\n",
      "SEX                           0\n",
      "EDUCATION                     0\n",
      "MARRIAGE                      0\n",
      "AGE                           0\n",
      "PAY_0                         0\n",
      "PAY_2                         0\n",
      "PAY_3                         0\n",
      "PAY_4                         0\n",
      "PAY_5                         0\n",
      "PAY_6                         0\n",
      "BILL_AMT1                     0\n",
      "BILL_AMT2                     0\n",
      "BILL_AMT3                     0\n",
      "BILL_AMT4                     0\n",
      "BILL_AMT5                     0\n",
      "BILL_AMT6                     0\n",
      "PAY_AMT1                      0\n",
      "PAY_AMT2                      0\n",
      "PAY_AMT3                      0\n",
      "PAY_AMT4                      0\n",
      "PAY_AMT5                      0\n",
      "PAY_AMT6                      0\n",
      "default payment next month    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv('../files/input/train_data.csv.zip', index_col = False, compression = \"zip\")\n",
    "data_test = pd.read_csv(\"../files/input/test_data.csv.zip\", index_col = False, compression = \"zip\")\n",
    "\n",
    "print(data_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_train.rename(columns={\"default payment next month\": \"default\"}, inplace=True)\n",
    "data_test.rename(columns={\"default payment next month\": \"default\"}, inplace=True)\n",
    "data_train.drop(columns=['ID'], inplace=True)\n",
    "data_test.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "data_train['EDUCATION'] = data_train['EDUCATION'].apply(lambda x: x if x > 0 else np.nan)\n",
    "data_test['EDUCATION'] = data_test['EDUCATION'].apply(lambda x: x if x > 0 else np.nan)\n",
    "\n",
    "data_train['MARRIAGE'] = data_train['MARRIAGE'].apply(lambda x: x if x > 0 else np.nan)\n",
    "data_test['MARRIAGE'] = data_test['MARRIAGE'].apply(lambda x: x if x > 0 else np.nan)\n",
    "\n",
    "data_train['EDUCATION'] = data_train['EDUCATION'].apply(lambda x: 4 if x > 4 else x)\n",
    "data_test['EDUCATION'] = data_test['EDUCATION'].apply(lambda x: 4 if x > 4 else x)\n",
    "\n",
    "data_train.dropna(inplace=True)\n",
    "data_test.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 2. División datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#particionamiento de los datos\n",
    "x_train = data_train.drop(columns=['default'])\n",
    "y_train = data_train[\"default\"]\n",
    "x_test = data_test.drop(columns=['default'])\n",
    "y_test = data_test[\"default\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 3. Creación pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "numerical_features = list(set(x_test.columns) - set(categorical_features))\n",
    "\n",
    "preprocesamiento = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('categoricas', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('numericas', StandardScaler(), numerical_features)\n",
    "    ],\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocesamiento),\n",
    "    ('pca', PCA(n_components = None)),\n",
    "    ('selector', SelectKBest(f_classif)),\n",
    "    ('svc', SVC(random_state=97))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 4. Optimización parametros con cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, balanced_accuracy_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "param_grid = {'pca__n_components': [None],\n",
    "                'selector__k': [17],\n",
    "                'svc__gamma': ['scale', 'auto', 0.01, 0.1, 1, 10]}\n",
    "              \n",
    "modelo = GridSearchCV(pipeline, param_grid, cv=10, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "modelo.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 5. Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "dir_path = '../files/models'\n",
    "\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "    with gzip.open('../files/models/model.pkl.gz', 'wb') as f:\n",
    "        pickle.dump(modelo, f)\n",
    "else:\n",
    "    with gzip.open('../files/models/model.pkl.gz', 'wb') as f:\n",
    "        pickle.dump(modelo, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 6. Cálculo de metricas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, balanced_accuracy_score, recall_score, f1_score\n",
    "import json\n",
    "\n",
    "y_train_pred = modelo.predict(x_train)\n",
    "y_test_pred = modelo.predict(x_test)\n",
    "\n",
    "train_metrics = {\n",
    "    \"type\": \"metrics\", \n",
    "    'dataset': 'train',\n",
    "    'precision': precision_score(y_train, y_train_pred),\n",
    "    'balanced_accuracy': balanced_accuracy_score(y_train, y_train_pred),\n",
    "    'recall': recall_score(y_train, y_train_pred),\n",
    "    'f1_score': f1_score(y_train, y_train_pred)\n",
    "}\n",
    "\n",
    "\n",
    "test_metrics = {\n",
    "    \"type\": \"metrics\", \n",
    "    'dataset': 'test',\n",
    "    'precision': precision_score(y_test, y_test_pred),\n",
    "    'balanced_accuracy': balanced_accuracy_score(y_test, y_test_pred),\n",
    "    'recall': recall_score(y_test, y_test_pred),\n",
    "    'f1_score': f1_score(y_test, y_test_pred)\n",
    "}\n",
    "\n",
    "output_path = '../files/output/metrics.json'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True) \n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_metrics, f, ensure_ascii=False) \n",
    "    f.write('\\n')\n",
    "    json.dump(test_metrics, f, ensure_ascii=False) \n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 7. Cálculo de matrices de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_cm = confusion_matrix(y_train, y_train_pred)\n",
    "test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "train_cm_dict = {\n",
    "    'type': 'cm_matrix',\n",
    "    'dataset': 'train',\n",
    "    'true_0': {'predicted_0': int(train_cm[0, 0]), 'predicted_1': int(train_cm[0, 1])},\n",
    "    'true_1': {'predicted_0': int(train_cm[1, 0]), 'predicted_1': int(train_cm[1, 1])}\n",
    "}\n",
    "\n",
    "test_cm_dict = {\n",
    "    'type': 'cm_matrix',\n",
    "    'dataset': 'test',\n",
    "    'true_0': {'predicted_0': int(test_cm[0, 0]), 'predicted_1': int(test_cm[0, 1])},\n",
    "    'true_1': {'predicted_0': int(test_cm[1, 0]), 'predicted_1': int(test_cm[1, 1])}\n",
    "}\n",
    "\n",
    "output_path = '../files/output/metrics.json'\n",
    "\n",
    "with open(output_path, 'a', encoding='utf-8') as f:\n",
    "    json.dump(train_cm_dict, f, ensure_ascii=False) \n",
    "    f.write('\\n')\n",
    "    json.dump(test_cm_dict, f, ensure_ascii=False)  \n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pca__n_components': None, 'selector__k': 17, 'svc__gamma': 0.1}\n",
      "0.6502443499687053\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('categoricas',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['SEX', 'EDUCATION',\n",
      "                                                   'MARRIAGE']),\n",
      "                                                 ('numericas', StandardScaler(),\n",
      "                                                  ['PAY_6', 'BILL_AMT3',\n",
      "                                                   'PAY_AMT6', 'PAY_3',\n",
      "                                                   'BILL_AMT1', 'PAY_AMT2',\n",
      "                                                   'BILL_AMT6', 'BILL_AMT4',\n",
      "                                                   'LIMIT_BAL', 'PAY_4',\n",
      "                                                   'PAY_2', 'PAY_AMT5', 'PAY_5',\n",
      "                                                   'PAY_0', 'BILL_AMT2',\n",
      "                                                   'PAY_AMT3', 'BILL_AMT5',\n",
      "                                                   'PAY_AMT4', 'PAY_AMT1',\n",
      "                                                   'AGE'])])),\n",
      "                ('pca', PCA()), ('selector', SelectKBest(k=17)),\n",
      "                ('svc', SVC(gamma=0.1, random_state=97))])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#prueba\n",
    "print(modelo.best_params_)\n",
    "print(modelo.best_score_)\n",
    "print(modelo.best_estimator_)\n",
    "print(modelo.best_index_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
